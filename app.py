from dotenv import load_dotenv
import os
import streamlit as st
import cohere
import shutil
import uuid
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma

# Load environment variables from .env file
load_dotenv()

# Fetch Cohere API key from environment
cohere_api_key = os.getenv("COHERE_API_KEY")
if not cohere_api_key:
    st.error("COHERE_API_KEY environment variable not found. Please set it before running the app.")
    st.stop()

# Initialize Cohere client
co = cohere.Client(cohere_api_key)

st.set_page_config(page_title="PDF Q&A with Cohere", layout="wide")

class CohereEmbeddings:
    """Custom Cohere embeddings wrapper compatible with LangChain-like interface."""

    def embed_documents(self, texts):
        try:
            response = co.embed(texts=texts, model="embed-english-v2.0")
            return response.embeddings
        except Exception as e:
            st.error(f"Error during embedding: {e}")
            return [[] for _ in texts]

    def embed_query(self, text):
        res = co.embed(texts=[text], model="embed-english-v2.0")
        return res.embeddings[0]

def get_user_session_id():
    """Generate or retrieve a unique session ID for the user."""
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    return st.session_state.session_id

def get_user_temp_dir():
    """Create and return user-specific temporary directory."""
    session_id = get_user_session_id()
    user_temp_dir = os.path.join("/tmp", f"user_{session_id}")

    # Create directory if it doesn't exist
    os.makedirs(user_temp_dir, exist_ok=True)
    return user_temp_dir

def cleanup_user_temp_dir():
    """Clean up all files in user's temporary directory."""
    user_temp_dir = get_user_temp_dir()
    if os.path.exists(user_temp_dir):
        # Remove all files in the directory
        for filename in os.listdir(user_temp_dir):
            file_path = os.path.join(user_temp_dir, filename)
            try:
                if os.path.isfile(file_path):
                    os.remove(file_path)
                elif os.path.isdir(file_path):
                    # Force remove directory even if files are locked
                    shutil.rmtree(file_path, ignore_errors=True)
            except Exception as e:
                # Silently ignore file locking errors
                pass

def load_pdf_chunks(pdf_path):
    """Load PDF and split into chunks."""
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = splitter.split_documents(pages)
        return chunks
    except Exception as e:
        st.error(f"Error loading PDF: {e}")
        return []

def get_vectorstore(chunks):
    """Create a new Chroma vector store from document chunks."""
    embeddings = CohereEmbeddings()
    session_id = get_user_session_id()
    # Create unique collection name for this user session
    collection_name = f"pdf_collection_{session_id}_{uuid.uuid4().hex[:8]}"

    # Create in-memory vector store to avoid file locking issues
    return Chroma.from_documents(
        chunks,
        embeddings,
        collection_name=collection_name
    )

def answer_query(question, relevant_docs):
    """
    Use retrieved chunks as context and get answer from Cohere chat model.
    """
    context = "\n\n".join([doc.page_content for doc in relevant_docs])

    prompt = f"""You are a helpful PDF assistant. Answer the question based on the provided context from the uploaded PDF.

Context from PDF:
{context}

Question: {question}

Instructions:
- If the context contains relevant information, provide a helpful answer
- If the context doesn't contain the specific information asked about, explain what the PDF actually contains instead
- If the PDF contains Lorem Ipsum or placeholder text, mention that and suggest uploading a real document
- Be conversational and helpful, not overly rigid

Answer:"""

    try:
        response = co.chat(
            model="command-xlarge-nightly",
            message=prompt,
            max_tokens=500,
            temperature=0.3
        )
        return response.text.strip()
    except Exception as e:
        return f"Error generating answer: {e}"

def main():
    st.title("üìÑ PDF Question & Answer with Cohere")

    st.markdown(
        """
        Upload a PDF file, ask questions about its content, and get answers generated by Cohere
        based solely on the content in the PDF using semantic search.
        """
    )

    # Add a button to clear previous uploads
    if st.button("üóëÔ∏è Clear Previous Files"):
        cleanup_user_temp_dir()
        # Clear ALL session state related to files and vectorstore
        keys_to_remove = ['vectorstore', 'current_file', 'processed_file'] + \
                         [k for k in st.session_state.keys() if k.startswith(('pdf_', 'chunks_'))]

        for key in keys_to_remove:
            if key in st.session_state:
                del st.session_state[key]

        st.success("Previous files cleared!")
        st.rerun()

    uploaded_file = st.file_uploader("Upload your PDF file", type=["pdf"])

    if uploaded_file is not None:
        # Check if this is a new file
        file_changed = ('current_file' not in st.session_state or
                        st.session_state.current_file != uploaded_file.name)

        if file_changed:
            # New file uploaded, clean up previous files
            cleanup_user_temp_dir()
            st.session_state.current_file = uploaded_file.name

            # Force remove old vectorstore from session state
            if 'vectorstore' in st.session_state:
                del st.session_state.vectorstore

            # Clear any other cached data
            for key in list(st.session_state.keys()):
                if key.startswith('pdf_') or key.startswith('chunks_'):
                    del st.session_state[key]

        # Save uploaded PDF to user-specific temporary directory
        user_temp_dir = get_user_temp_dir()
        temp_file_path = os.path.join(user_temp_dir, uploaded_file.name)

        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(f"PDF uploaded successfully: {uploaded_file.name}")

        # Load and process PDF only if not already done for THIS file
        if ('vectorstore' not in st.session_state or
                st.session_state.get('processed_file') != uploaded_file.name):

            with st.spinner("Processing PDF..."):
                # Load and chunk PDF
                chunks = load_pdf_chunks(temp_file_path)

                if chunks:
                    # Create vector store and store in session state
                    st.session_state.vectorstore = get_vectorstore(chunks)
                    st.session_state.processed_file = uploaded_file.name
                    st.success("PDF processed and ready for questions!")
                else:
                    st.error("Failed to process the PDF. Please check the file or try another.")
                    return

        # Input question from user
        if 'vectorstore' in st.session_state:
            question = st.text_input("Ask a question based on the PDF content:")

            if st.button("Get Answer") and question.strip() != "":
                with st.spinner("Searching and generating answer..."):
                    # Find relevant chunks by semantic similarity
                    relevant_docs = st.session_state.vectorstore.similarity_search(question, k=3)

                    # Get answer using Cohere chat API
                    answer = answer_query(question, relevant_docs)

                st.markdown("### Answer:")
                st.write(answer)



if __name__ == "__main__":
    main()